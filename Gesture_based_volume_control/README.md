Gesture-Based Volume Control ğŸšï¸ğŸ–ï¸
A Python project that controls your system volume by detecting hand gestures using your webcam!
Move your thumb and index finger closer or farther to decrease or increase the volume dynamically.
Built with OpenCV, MediaPipe, PyCaw, and hand tracking modules.

ğŸ“¸ Demo
(You can add a GIF or screenshot here showing the app in action!)

ğŸ“‚ Project Structure
bash
Copy
Edit
GestureBasedVolumeControl/
â”œâ”€â”€ main.py                # Main file to run the application
â”œâ”€â”€ requirements.txt       # List of required Python libraries
â”œâ”€â”€ HandTrackingSheerin/   # Custom hand tracking module
â””â”€â”€ README.md              # Project description (this file)
ğŸ› ï¸ Technologies Used
Python 3.8+

OpenCV â€“ for video capture and drawing

MediaPipe â€“ for real-time hand tracking

NumPy â€“ for mathematical operations

PyCaw â€“ to control system audio (Windows only)

Math â€“ for distance calculation between fingers

comtypes â€“ for COM interface with system volume

âœ¨ Features
Detects hand landmarks in real-time using your webcam.

Measures the distance between thumb and index fingertips.

Dynamically maps the distance to volume percentage (0â€“100%).

Visual feedback:

Circle on thumb and index finger.

Line between fingers.

Volume bar showing current volume.

Real-time FPS displayed on the screen.

Smooth volume control without any physical contact with your system!

ğŸ”¥ How It Works
Hand Detection:
Using HandTrackingSheerin, your hand is detected, and landmarks (points on fingers) are identified.

Distance Calculation:
The distance between the tip of the thumb (id=4) and the tip of the index finger (id=8) is calculated using the Pythagoras theorem (math.hypot).

Volume Mapping:
The measured distance (between 40 to 200 pixels) is mapped to a volume range (0% to 100%) using numpy.interp().

Volume Adjustment:
Volume is updated in real-time through PyCaw, directly controlling your Windows system volume.

Visual Interface:
Real-time drawing on webcam feed â€” finger positions, connection line, volume percentage, and a dynamic volume bar.

ğŸš€ Getting Started
1. Clone the repository
bash
Copy
Edit
git clone https://github.com/your-username/GestureBasedVolumeControl.git
cd GestureBasedVolumeControl
2. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
Or install individually:

bash
Copy
Edit
pip install opencv-python mediapipe pycaw comtypes numpy
3. Run the Project
bash
Copy
Edit
python main.py
ğŸ“œ Requirements
Operating System: Windows (PyCaw is Windows-specific)

Python: 3.8 or higher

Webcam: Internal or external webcam required

âš¡ Controls
Bring thumb and index finger close â†’ Volume decreases

Move thumb and index finger apart â†’ Volume increases

Press 'q' â†’ Exit the application

ğŸ“‹ Notes
The project uses a custom hand tracking module (HandTrackingSheerin) based on MediaPipe for detecting hands.

The volume bar and percentage provide visual feedback for better interaction.
Accuracy may depend on lighting conditions and webcam quality.

ğŸ¯ Future Improvements
Add volume mute with specific gesture (e.g., closed fist âœŠ).

Add gesture calibration for different users.

Make it cross-platform (support macOS/Linux).

Add support for media controls (play/pause/next/previous).
